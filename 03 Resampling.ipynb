{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5N8uXaLdary"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/univiemops/tewa1-computational-cognition/blob/main/03%20Resampling.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Tutorial 3 - Resampling methods and Data Visualization\n",
    "\n",
    "*Written and revised by Jozsef Arato, Mengfan Zhang, Dominik Pegler*  \n",
    "Computational Cognition Course, University of Vienna  \n",
    "https://github.com/univiemops/tewa1-computational-cognition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVRiO-appks7"
   },
   "source": [
    "## This week's lab:\n",
    "\n",
    "We will introduce you to two common resampling methods: **Bootstrapping** and **Permutation test** (an alternative to the t-test) with data visualization of them. Resampling techniques are powerful tools for estimating the sampling distribution of a statistic, making inferences about population parameters, validating models, and other situations where traditional parametric assumptions are not met or when exact analytical solutions are impractical. \n",
    "\n",
    "In this notebook, we have included many explanations as comments in the code cell. Please read them carefully instead of just pressing the run button.  \n",
    "\n",
    "**Learning goals:** \\\n",
    "When finishing this tutorial, you should be able to ...\n",
    "* use `random` functions to generate samples\n",
    "* perform a bootstrap and estimate the variance \n",
    "* perform a permutation test and determine the statistical significance of models\n",
    "\n",
    "\n",
    "**Estimated time to complete:** 2 hours \\\n",
    "**Deadline:** Next Wednesday, 10:00\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sampling\n",
    "\n",
    "Sampling is the process of selecting a subset of values or items from a larger population. Python has various libraries to do sampling, a commonly used one is `numpy.random` module. Let's import the libraries first and have a look at some useful functions that we will use a lot in this course (or have used before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-D3BwIshN_C"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we randomly sample items from an array. This means that each item in the array has an equal chance of being selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.arange(20)\n",
    "\n",
    "# Without replacement\n",
    "# Selected item will not be in the “pool” for selection\n",
    "sample_1 = np.random.choice(my_array)\n",
    "print(\"Randomly chosen item without replacement:\", sample_1)\n",
    "\n",
    "# With replacementare\n",
    "# Selected item put back into the \"pool\" before another item is selected\n",
    "sample_2 = np.random.choice(my_array, size=5, replace=True)\n",
    "print(\"Randomly chosen items with replacement:\", sample_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also generate random samples from a given distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample from a uniform distribution\n",
    "sample_3 = np.random.uniform(low=0.0, high=10, size=10)\n",
    "print(\"Randomly chosen items from a uniform distribution:\", \"\\n\", sample_3, \"\\n\")\n",
    "\n",
    "# Randomly sample from a normal distribution\n",
    "sample_4 = np.random.normal(\n",
    "    loc=0.0, scale=1.0, size=10\n",
    ")  # loc and scale are the mean and sd of the distribution\n",
    "print(\"Randomly chosen items from a noraml distribution:\", \"\\n\", sample_4, \"\\n\")\n",
    "\n",
    "# Randomly sample from a beta distribution\n",
    "sample_5 = np.random.beta(a=0.5, b=0.5, size=10)\n",
    "print(\"Randomly chosen items from a beta distribution:\", \"\\n\", sample_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to generate a centrain format of numbers with a range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random integers within the range of low (inclusive) to high (exclusive)\n",
    "sample_6 = np.random.randint(low=5, high=17, size=10)\n",
    "print(\"Randomly chosen integers from 5 to 17:\", \"\\n\", sample_6, \"\\n\")\n",
    "\n",
    "# Generate floats within the range from 0 (inclusive) to 1 (exclusive)\n",
    "sample_7 = np.random.random_sample(size=10)\n",
    "print(\"Randomly chosen floats from 0 to 1:\", \"\\n\", sample_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful function is `random.shuffle`, you can run the code below several times to figure out what this function does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.arange(20)\n",
    "print(\"The original array:\", my_array)\n",
    "\n",
    "np.random.shuffle(my_array)\n",
    "print(\"After randomly shuffling:\", my_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we'd like to introduce here is `random.seed`, which we already used for last week. Random seed is used to generate pseudo-random numbers. If you provide the same seed value, you'll get the same sequence of random numbers each time you run your code. You can change the seed value back and forth, run the code below several times to see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sample_8 = np.random.random_sample(size=10)\n",
    "print(\"After randomly shuffling with setting a seed:\", sample_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bootstrapping\n",
    "\n",
    "Imagine you conducted an experiment in which you collected reaction time data from two small groups of participants under different manipulations. You compare the means of these two groups and find a difference, and you think the difference is due to the manipulation. However, it is also possible that one or two participants in one group didn't sleep well last night, weren't in good health, weren't paying attention, or some other random thing that you can't control. One thing you can do is repeat the experiment (maybe over and over again) to try to rule out the effect of random things. Fortunately, you have another much easier and less expensive option, which is to bootstrap. \n",
    "\n",
    "Bootstrapping is a technique used to estimate the sampling distribution of almost any statistic by repeatedly sampling with replacement from the observed data. It gives you a sense of what might happen if you repeated an experiment many times, and allows you to assess the variability and uncertainty associated with the statistic. Now let's perform bootstrapping procedures step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have some reaction time data from an experiment\n",
    "np.random.seed(213)\n",
    "rt_data = np.random.randint(150, 600, 20)\n",
    "exp_mean = rt_data.mean()\n",
    "print(\"Experimental reaction time data:\", \"\\n\", rt_data)\n",
    "print(\"Mean of experimental reaction time\", \"\\n\", exp_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform bootstrapping sampling\n",
    "n_samples = 100  # perform the sampling 100 times, it works like repeating the experiment 100 times\n",
    "bootstrap_means = np.zeros(n_samples)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Step 1: Sampling with replacement to create a bootstrap sample\n",
    "    current_bootstrap_sample = np.random.choice(\n",
    "        rt_data, size=rt_data.size, replace=True\n",
    "    )\n",
    "\n",
    "    # Step 2: Calculate the statistic of interest for each sample\n",
    "    current_mean = np.mean(current_bootstrap_sample)\n",
    "\n",
    "    # Step 3: Store each sample statistic for estimating the sampling distribution\n",
    "    bootstrap_means[i] = current_mean\n",
    "\n",
    "# Step 4: Drawing Inferences\n",
    "estimated_mean = np.mean(bootstrap_means)\n",
    "estimated_std = np.std(bootstrap_means)\n",
    "\n",
    "print(\"Estimated bootstrap mean :\", estimated_mean)\n",
    "print(\"Standard error of the estimate:\", estimated_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sampling distribution of the statisitc\n",
    "plt.hist(bootstrap_means)\n",
    "plt.axvline(x=exp_mean, color=\"r\", label=\"exp_mean\")\n",
    "plt.ylim((0, 30))\n",
    "plt.xlabel(\"Means\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distributions\", fontsize=15)\n",
    "plt.legend([\"exp_mean\", \"bootstrap_mean\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We just did our first bootstrap! In real practice, instead of writing a loop, Python `Scipy.stats` module provides the `bootstrap` function to do it easily. `Scipy` bulids on the functionality of `NumPy` but extends it by offering a wide range of specialized functions and algorithms for scientific and technical computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "bootstrap_out = stats.bootstrap(\n",
    "    data=(rt_data,), statistic=np.mean, n_resamples=100, axis=0\n",
    ")  # check out ?bootstrap as well\n",
    "print(bootstrap_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you do a bootstrap with 50 samples, calculate the standard deviation and store it in the variable \"bootstrap_std\"? It doesn't matter if you use the loop or the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Permutation test\n",
    "\n",
    "A permutation test is a **non-parametric** method used to assess the significance of an observed result by randomly shuffling the data and recalculating the statistic of interest multiple times. Compared to parametric methods (e.g., t-test, ANOVA), non-parametric methods do not have assumptions about the underlying distribution or the homogeneity of variance, but only assume the exchangeability within the data. Exchagenability means the prior values won't affect the future outcomes. For example, if you toss a coin, previous outcomes won't affect which side you will get this time. However, if you have time series data or spatial data with autocorrelation, a permutation test may not be appropriate. In general, permutation is robust and very useful when the assumptions of parametric test are not met, or when the sample size is small. \\\n",
    "Let's have a look at how to perform a permutation test using two reaction times datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQZdWFChr2y3"
   },
   "outputs": [],
   "source": [
    "# Below, we have reaction time data for the treatment and control groups, using a between subject design\n",
    "treatment = np.array(\n",
    "    [\n",
    "        444.48703626,\n",
    "        420.71413104,\n",
    "        482.04432447,\n",
    "        380.46896668,\n",
    "        420.56864234,\n",
    "        474.09130417,\n",
    "        414.9748433,\n",
    "        450.15423802,\n",
    "        436.53977461,\n",
    "        500.12705411,\n",
    "        405.00705696,\n",
    "        419.3141794,\n",
    "        460.46096974,\n",
    "        450.54358948,\n",
    "        420.93431563,\n",
    "        467.40481135,\n",
    "        510.84094939,\n",
    "        482.61924772,\n",
    "        480.32638462,\n",
    "        510.76756724,\n",
    "    ]\n",
    ")\n",
    "\n",
    "control = np.array(\n",
    "    [\n",
    "        420.1243685,\n",
    "        501.25211241,\n",
    "        454.37132587,\n",
    "        600.39850065,\n",
    "        501.79657108,\n",
    "        481.94197109,\n",
    "        469.51703441,\n",
    "        449.82747137,\n",
    "        450.98838458,\n",
    "        477.15878941,\n",
    "        570.00039675,\n",
    "        460.18766471,\n",
    "        432.70480616,\n",
    "        480.38394358,\n",
    "        478.46070285,\n",
    "        485.71067427,\n",
    "        487.91937261,\n",
    "        505.86604195,\n",
    "        495.8480102,\n",
    "        480.9547509,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could you do some data exploration on these two groups in the cell below:\n",
    "\n",
    "1. Calculate the mean and standard deviation for the treatment and control groups and store the results in the variables \"tmt_mean\", \"cl_mean\", \"tmt_sd\", \"cl_sd\", respectively.\n",
    "2. Calculate the absolute difference in means between the groups and store it in the \"true_diff\" variable.\n",
    "3. Create two subplots, each plot showing a histogram for each group. You can customize your plot, but be sure to set the same ranges for the x (370, 610) and y (0, 8) axes for both plots. We provide some code to do this, and compare your plot with the plot (we set 10 bins for histograms) from the test cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Subplots\n",
    "plt.figure(figsize=(12, 5))  # create a new figure with a certain size\n",
    "plt.subplot(\n",
    "    1, 2, 1\n",
    ")  # subplot(nrows, ncols, index), create subplots on a grid with nrows rows and ncols columns, the current plot take the index position\n",
    "# YOUR CODE HERE: plot a histogram for the treatment group\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# YOUR CODE HERE: plot a histogram for the control group\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> The cell below tests if your code is correct or not. Just run the cell, and it will give you an error message or a compliment.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell\n",
    "tests = np.load(\"Answers/week3.npy\", allow_pickle=True)\n",
    "out = [tmt_mean, cl_mean, tmt_sd, cl_sd, true_diff]\n",
    "\n",
    "try:\n",
    "    assert (out == tests[0:5]).all()\n",
    "except AssertionError as msg:\n",
    "    print(\"At least one variable was not correctly calculated, check your code again!\")\n",
    "    raise (msg)\n",
    "else:\n",
    "    print(\"Good job!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell, and compare your plot with the plot blow\n",
    "image = plt.imread(\"Answers/tmt_cl_plot.png\")\n",
    "plt.figure(figsize=(15, 6.25))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PMS-S8_U9To"
   },
   "source": [
    "We can also visualize the means with error bars showing the standard deviation. To do this, we use the `plt.errorbar` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "eyb8irbNTcU4",
    "outputId": "cfb90453-cdda-42e6-b998-1eae1f4fc2c0"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(\n",
    "    x=0, y=np.mean(treatment), yerr=np.std(treatment), marker=\"o\", markersize=10\n",
    ")\n",
    "plt.errorbar(x=1, y=np.mean(control), yerr=np.std(control), marker=\"o\", markersize=10)\n",
    "plt.ylabel(\"reaction time (ms)\")\n",
    "plt.xlim([-1, 2])\n",
    "plt.xticks(np.arange(2), [\"Treatment\", \"Control\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sUdvtaKaqCY"
   },
   "source": [
    "It's also very convenient to create a more advanced boxplot using the `plt.boxplot` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "LICfG1_yZ3Xe",
    "outputId": "617eab8c-71d8-4009-9b2e-e15e1483abce"
   },
   "outputs": [],
   "source": [
    "plt.boxplot([treatment, control], labels=[\"Treatment\", \"Control\"])\n",
    "plt.title(\"Boxplot of Treatment and Control Groups\")\n",
    "plt.xlabel(\"Group\")\n",
    "plt.ylabel(\"Reaction time (ms)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, enough data exploration and plots for now. Let's get back to the permutation test. We will show you how to implement it in the cell below, and make sure you understand each step clearly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the observed statistic of interest\n",
    "obs_mean_diff = np.abs(\n",
    "    treatment.mean() - control.mean()\n",
    ")  # our example compare the means of two groups\n",
    "\n",
    "# Step 2: Combine the data from two groups\n",
    "combined_data = np.concatenate((treatment, control))  # check out ?np.concatenate\n",
    "\n",
    "# We initiate a loop here because we need to repeat step 3-5 many many times\n",
    "n_permutations = 1000\n",
    "permuted_means_diff = np.zeros(n_permutations)\n",
    "\n",
    "for i in range(n_permutations):\n",
    "    # Step 3: Randomly shuffle the combined data to mix up groups\n",
    "    np.random.shuffle(combined_data)\n",
    "\n",
    "    # Step 4: From the randomly shuffled data, generate 2 groups with the same size as the original groups\n",
    "    perm_group1 = combined_data[: len(treatment)]\n",
    "    perm_group2 = combined_data[len(treatment) :]\n",
    "\n",
    "    # Step 5: Calculate the statistic of interest from the 2 permuted groups and store the result from each permutation\n",
    "    permuted_means_diff[i] = perm_group1.mean() - perm_group2.mean()\n",
    "\n",
    "# Step 6: Calculate the p-value as the proportion of:\n",
    "# one-sided: permuted statistic greater than or less than your observed statistic\n",
    "# two-sided: permuted statistic greater than your observed statistic and less than your negative observed statistic\n",
    "p_value = (\n",
    "    np.sum(\n",
    "        np.sum(permuted_means_diff >= obs_mean_diff)\n",
    "        + np.sum(permuted_means_diff <= -obs_mean_diff)\n",
    "    )\n",
    "    / n_permutations\n",
    ")\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the p-value from the permutation test, could you manually perform a traditional t-test and compare the result to the above permutation test?   \n",
    "1. Calculate the t-statistic using the formula: $$ t = \\frac{\\bar{x_1} - \\bar{x_2}}{\\sqrt{\\frac{s_1^2}{n_1 - 1} + \\frac{s_2^2}{n_2 - 1}}} $$\n",
    "2. Convert the t-statistic to the p-value using the function: `scipy.stats.t.sf(t, df)`. This function will give you a one-sided p-value, just multiply by 2 to get the two-sided p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we perform a two-sample independent t-test, you can compare your calculation with it, they should be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(treatment, control, alternative=\"two-sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is done, we can also evaluate the result of the permutations visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "J-ibZHs4vnsr",
    "outputId": "67b43496-596a-4a67-969b-6fcc60e2ca22"
   },
   "outputs": [],
   "source": [
    "plt.hist(permuted_means_diff, bins=100)  # distribution of permutated differences\n",
    "plt.axvline(\n",
    "    obs_mean_diff, color=\"red\"\n",
    ")  # mark the observed difference on the histogram with a vertical line\n",
    "plt.axvline(-obs_mean_diff, color=\"red\")\n",
    "plt.axvline(\n",
    "    np.percentile(permuted_means_diff, 5), color=\"black\", linestyle=\"dashed\"\n",
    ")  # np.percentile calcultes the q-th% of the input array\n",
    "plt.axvline(np.percentile(permuted_means_diff, 95), color=\"black\", linestyle=\"dashed\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the last thing we want to tell you about the permutation test is that instead of writing a loop, `scipy.stats` also provides a function to do the permutation test easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first write a function to determine the statistic to test\n",
    "def statistic(x, y):\n",
    "    return np.mean(x) - np.mean(y)\n",
    "\n",
    "\n",
    "# Then call the permutation test function\n",
    "per_test = scipy.stats.permutation_test(\n",
    "    (treatment, control),\n",
    "    statistic,\n",
    "    permutation_type=\"independent\",\n",
    "    n_resamples=1000,\n",
    "    alternative=\"two-sided\",\n",
    ")\n",
    "\n",
    "print(\"Observed mean difference:\", per_test.statistic)\n",
    "print(\"p-value from the permutation test:\", per_test.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you do a permutation test on the correlation between the treatment and control groups with 1000 resamples\"? It doesn't matter if you use the loop or the function. Hint: You may need the `np.corrcoef` function, check out how to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CORE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RY2zbNRszYAS"
   },
   "source": [
    "## Homework 1\n",
    "\n",
    "### Functions\n",
    "now we are ready with the permutation test, now \"re-cycle\" your code from above, to make it into a function below.\n",
    "\n",
    "This function should take 2 inputs (the 2 data-sets),\n",
    "do the permuations as above, and return the permuted p-value.\n",
    "\n",
    "Remember you can choose whatever variable names within the function, but best practice is not to use the same ones as for the code outside the function!\n",
    "\n",
    "the function shoud not rely on any of the variables that are defined outside of the function: you can verify this by copy-pasting it into a new notebook and test it with some new data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0ChERI-zjlN"
   },
   "outputs": [],
   "source": [
    "def my_perm_test(#your code):\n",
    "  #your code \n",
    "  #your code \n",
    "  return #your code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9dgh9cn0ucA"
   },
   "source": [
    " verify that your function works, with comparing it with your previous code\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDBq2nCE0zYC"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geymltps8iHY"
   },
   "source": [
    "## now lets try the permutation test on some new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZAUXv0Ez5dc"
   },
   "outputs": [],
   "source": [
    "x1 = np.array(\n",
    "    [\n",
    "        200.48703626,\n",
    "        420.71413104,\n",
    "        482.04432447,\n",
    "        380.46896668,\n",
    "        420.56864234,\n",
    "        474.09130417,\n",
    "        414.9748433,\n",
    "        450.15423802,\n",
    "        436.53977461,\n",
    "        500.12705411,\n",
    "        405.00705696,\n",
    "        419.3141794,\n",
    "        460.46096974,\n",
    "        450.54358948,\n",
    "        420.93431563,\n",
    "        467.40481135,\n",
    "        510.84094939,\n",
    "        482.61924772,\n",
    "        480.32638462,\n",
    "        860.56161,\n",
    "    ]\n",
    ")\n",
    "\n",
    "x2 = np.array(\n",
    "    [\n",
    "        420.1243685,\n",
    "        501.25211241,\n",
    "        454.37132587,\n",
    "        900.39850065,\n",
    "        501.79657108,\n",
    "        481.94197109,\n",
    "        469.51703441,\n",
    "        449.82747137,\n",
    "        450.98838458,\n",
    "        477.15878941,\n",
    "        570.00039675,\n",
    "        460.18766471,\n",
    "        432.70480616,\n",
    "        480.38394358,\n",
    "        478.46070285,\n",
    "        485.71067427,\n",
    "        487.91937261,\n",
    "        505.86604195,\n",
    "        495.8480102,\n",
    "        1500.5446,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p42DGidL8lVc"
   },
   "source": [
    "explore these data-sets with histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9mNDGFT8qam"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7yhmPvI0mpp"
   },
   "source": [
    "now, we can easily use the function to compare other data-sets\n",
    "\n",
    "for example X1 and X2 above\n",
    "compare the result with the t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHXTt_Ec05DK"
   },
   "outputs": [],
   "source": [
    "my_perm_test(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm3iwopJtYhB"
   },
   "source": [
    "log transform data before running the statistics\n",
    "\n",
    "a common way to deal with data with large variability (eg: free viewing looking times) is to do a log transform.\n",
    "\n",
    "1. make a scatter plot with the original data on the X and the raw data on the Y axis \n",
    "add both datasets to the same figure (using different colors)\n",
    "\n",
    "\n",
    "2. run the permutation test and the t-test for the log-transformed datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD_J9m3-t8A9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRXtaYSht65d"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05KI0LFp2UVW"
   },
   "source": [
    "\n",
    "### optional function parameters\n",
    "\n",
    "until now we fixed the number of permutations in MyPermTest\n",
    "\n",
    "make a new function, MyPermTestv2, with the only difference that there is a 3rd input variable, that controls the number of permutations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrZDrIWz2T_y"
   },
   "outputs": [],
   "source": [
    "def my_perm_test_v2(#your code):\n",
    "    #your code\n",
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdPy2IRL25Q4"
   },
   "source": [
    "once this is done, make a visualization of how the permuted p value changes as you change the number of permutations\n",
    "\n",
    "\n",
    "1. use `my_perm_test_v2`, to compare data1 and data2, with the number of permutations changing from 50 to 3000 in steps of 200  (use np.arange and a for cycle), at each step you only need to calcualte the permuted p-value\n",
    "2. make a scatter plot, to visualize what you have calculate in 1.: the number of permutations on the x axis and the permuted p-value on the y-axis\n",
    "3. add a horizontal line, that crosses the whole figure and shows the p-value obtained by  t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMDYjSMz3iB5"
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "# your code\n",
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcIB9ZrZw5sZ"
   },
   "source": [
    "### Bootstrapped confidence interval \n",
    "\n",
    "calculate the bootstrapped confidence interval for the mean of Data 1 and Data 2 with 2000 bootstraps. \n",
    "You can use np.random.choice ot perform sampling with replacemen- check the slided for more info.\n",
    "\n",
    "after you have the 2000 sample means, you can use np.percentile to find the 95,99% confidence intervals\n",
    "\n",
    "visualize what you found: if you use errobar, not that you can define positive and negative error differently (as a boostrapped confidence interval is not symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4w32b1g89Jbh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "io0To_kloJ1a"
   },
   "source": [
    "## Homework 2 (advanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkQbwJ7K8tua"
   },
   "source": [
    "### Data simulation and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a5aYWHU4RIq"
   },
   "source": [
    "test permutation test and compare with the t-test with largely unequal sample sizes \n",
    "\n",
    "imagine a scenario where you research reaction times in a rare patient group\n",
    ",so that you only have 5 patients.. obviously it is easier to get a large number of control participants, lets say 50\n",
    "\n",
    "set mean=600 for patiens with SD of 100 (normal distribution)\n",
    "set mean=550 for control with SD of 100 (uniform distribution)\n",
    "\n",
    "1. make 2 data sets, patient group with N=5, the control group with N=50, \n",
    "2. compare them with the t-test\n",
    "3. compare them using the permutation test\n",
    "4. repeat this process multiple times, and systematically compare (with for cycle and visualization) the similarity between permuation and t-test result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRLYPopyxbHf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of TEWA- 1 Resampling_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
