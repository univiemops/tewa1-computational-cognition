{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVRiO-appks7"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/univiemops/tewa1-computational-cognition/blob/main/05%20Regression%20Simulation.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Tutorial 5 - Regression Simulation\n",
    "\n",
    "\n",
    "*Written and revised by Jozsef Arato, Mengfan Zhang, Dominik Pegler*  \n",
    "Computational Cognition Course, University of Vienna  \n",
    "https://github.com/univiemops/tewa1-computational-cognition\n",
    "\n",
    "---\n",
    "\n",
    "## This week's lab:\n",
    "\n",
    "We will show you how to perform linear regression with one or more predictors in Python. We will start by creating fake data using a regression model with known parameters, and then fit that data to another linear regression model and see how well we can recover the model parameters of the first model. This approach is very common and provides a benchmark for evaluating the performance of different models. After visualizing the regression and evaluating model performance, we will use bootstrapping to model confidence intervals around our parameter values to show how confident or certain we are about them. Finally, we will show you how to use regression models to test hypotheses.\n",
    "\n",
    "\n",
    "In this notebook, we have included many explanations as comments in the code cell. Please read them carefully instead of just pressing the run button.  \n",
    "\n",
    "**Learning goals:** \\\n",
    "When finishing this tutorial, you should ...\n",
    "* be able to generate synthetic data from a linear model\n",
    "* fit a linear model to data and evaluate it's performance\n",
    "* model uncertainty around your parameter estimates\n",
    "* test hypotheses with linear models\n",
    "\n",
    "\n",
    "**Deadline:** Day of next lab, 10:00\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-b9FuIi4otA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import linalg, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvUGMVG6zbvL"
   },
   "source": [
    "## 2. Simulating data based on a regression model\n",
    "\n",
    "In a linear model, you typically find an intercept (constant term) along with one or more coefficients (slopes) that multiply the predictor variables. With knowledge of these parameters and an understanding of the data's noise level (i.e., adding an error term), we can generate synthetic data. This allows us to compute a corresponding y-value for every x-value. In the formulas below, $X$ and $Y$ are capitalized and bolded because we are referring to vectors (or numpy arrays) containing multiple x and y values rather than single scalar values.\n",
    "\n",
    "* Equation for the predicted line:\n",
    "$Y_{pred}=B_0+B_1X$\n",
    "\n",
    "* Equation for the data generation:\n",
    "$Y=B_0+B_1X+Error$\n",
    "\n",
    "In our example, we are trying to predict the price of an apartment based on the age of the house. To start, we randomly generate the ages below for 150 houses, ranging from 0 to 200 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pKc-1MQzjBl"
   },
   "outputs": [],
   "source": [
    "n = 150\n",
    "age = np.random.randint(0, 200, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JDty602z5pd"
   },
   "source": [
    "Now we want to generate apartment prices for these 150 houses using a linear regression model. In our scenario, we know that, let's say \n",
    "\n",
    "1. a brand new apartment costs  EUR 500,000,\n",
    "2. the error in the model should have standard deviation of EUR 100,000, and\n",
    "3. for each additional year, the price is lowered by EUR 1,000.\n",
    "\n",
    "With this information, we are ready to go. A brand new apartment is 0 years old, so the price for an apartment with $age=0$ represents our intercept (`b0`). The price change per year is -EUR 1,000, which is our slope (`b1`), and the error, well ... Let's put everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUwIKSUp00iP"
   },
   "outputs": [],
   "source": [
    "b0 = 5_000_000\n",
    "b1 = -1_000\n",
    "sd = 100_000\n",
    "err = np.random.normal(0, sd, n)\n",
    "\n",
    "price = b0 + b1 * age + err\n",
    "\n",
    "price[:5]  # show the first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCE_aeGH1eAs"
   },
   "source": [
    "To get a better feel for what our data looks like, it's often useful to visualize it. We will use a scatterplot and also add some meaningful labels using Matplotlib, specifically its `pyplot` submodule, which we imported earlier under the alias `plt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Os77I6xGaS24",
    "outputId": "2d197f4d-4183-4ea2-bae5-7cfd64b86f7d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=age, y=price)\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"price (EUR)\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s3J-8n92P_3"
   },
   "source": [
    "## 3. Fitting a regression line\n",
    "\n",
    "Next, we fit the data to a regression model using least squares estimation – `linalg.lstsq()`. This requires adding a column of ones to the predictor variable. For now, it doesn't matter much why, but for those who are interested: the reason is that regression models are computed as a matrix-vector multiplication for efficiency, and adding a column of ones is a way to include the intercept term (`b0`) in the matrix equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHONvp992cen",
    "outputId": "91383144-0b26-41fb-e54b-3cf3a317ea87"
   },
   "outputs": [],
   "source": [
    "X = np.column_stack((np.ones(n), age))\n",
    "print(np.shape(X))\n",
    "reg_result = linalg.lstsq(X, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIXqX65beqES",
    "outputId": "833720fb-852c-40e1-c3af-efdf3eecce54"
   },
   "outputs": [],
   "source": [
    "X[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlQOqA7XfkfF"
   },
   "outputs": [],
   "source": [
    "?linalg.lstsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "028kuDEG2xUB"
   },
   "source": [
    "The first argument that is returned by `lstsq()` is the most important one for us now. `print()` it out (it should contain two values), the 2nd argument is the residual (error), `print()` it out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3wCTTFR3dup",
    "outputId": "cbadf0bc-ad6b-4095-95c0-519dd4cf3523"
   },
   "outputs": [],
   "source": [
    "print(reg_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWMw8Nfef3JU",
    "outputId": "e9273288-388e-4c44-b763-489adc54566f"
   },
   "outputs": [],
   "source": [
    "reg_result[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNo8liAm2aGX"
   },
   "source": [
    "<div class=\"alert alert-info\">Hopefully you can see that we got similar values to what we used to create the data, but not exactly the same.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyI407583wpB"
   },
   "source": [
    "## 4. Visualizing the regression line\n",
    "1. Use the scatterplot again to visualize the age-price data, as before,\n",
    "2. add the regression line based on the result of `lstsq()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "tQP-Gk1vhgJU",
    "outputId": "d1fdb98c-8839-449d-ee79-93a0be438c7f"
   },
   "outputs": [],
   "source": [
    "price_pred = reg_result[0][0] + reg_result[0][1] * age\n",
    "\n",
    "\n",
    "plt.scatter(age, price)\n",
    "plt.plot(age, price_pred, color=\"r\")\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"price €\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vzmwZWzhdkW"
   },
   "outputs": [],
   "source": [
    "residuals = price - price_pred\n",
    "\n",
    "residuals[:5]  # show the first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOge9U8GNr78"
   },
   "source": [
    "## 5. Calculate the residuals and the total error for the fitted model\n",
    "\n",
    "Use the `c=` argument of `plt.scatter()` to color dots based on the residual error. This can be done using `plt.plot()`, but you will need some care how you include the values in $X$ (as they are in random order). You can also try it with the squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "fQeFqFWVNp9t",
    "outputId": "896f3a79-2e09-4c30-e49d-1db74585ccca"
   },
   "outputs": [],
   "source": [
    "plt.scatter(age, price, c=residuals**2)\n",
    "plt.plot(age, price_pred, color=\"r\")\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"price (EUR)\", fontsize=14)\n",
    "plt.colorbar().set_label(\"squared residuals\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BMudU6ZueE9"
   },
   "source": [
    "Let's compare what you calculated with the output of `linalg.lstsq()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3iQe278uk0d",
    "outputId": "dd226dd0-8981-47de-e5be-da5c56a70739"
   },
   "outputs": [],
   "source": [
    "print(reg_result[1])\n",
    "\n",
    "print(np.sum((price - price_pred) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWb1SLDXMHSI"
   },
   "source": [
    "## 6. Bootstrapping regression lines\n",
    "\n",
    "<div class=\"alert-warning alert\">Advanced! No obligation to complete this!</div>\n",
    "\n",
    "To get a sense of how confident we can be in our regression line, we will bootstrap many times from our original data set, calculating and plotting a new regression line at each iteration. You should see many different lines on the same plot. E.g., you can use `np.random.choice()` at each iteration to create `n` – that's the number of data points in the original dataset – indices. With these indices you could then create bootstrapped arrays for age etc. at each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "ZfSEEeXMMa8O",
    "outputId": "95fe11ed-ea76-4bc4-9592-ff4a4c912316"
   },
   "outputs": [],
   "source": [
    "n_sim=100\n",
    "\n",
    "for i in range(n_sim, n):\n",
    "    boostrapped_idx = # YOUR CODE\n",
    "    boostrapped_age = # YOUR CODE\n",
    "    boostrapped_price = # YOUR CODE\n",
    "    boostrapped_age_n = np.stack([boostrapped_age,np.ones(n)], axis=1)\n",
    "    coeff,total_error,_,_ = # YOUR CODE\n",
    "    boostrapped_price_pred = # YOUR CODE\n",
    "\n",
    "    plt.plot(boostrapped_age,boostrapped_price_pred, c=\"red\", alpha=0.05)\n",
    "\n",
    "plt.scatter(boostrapped_age,boostrapped_price)\n",
    "plt.plot(age,price_pred, c=\"black\", linestyle=\"--\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.xlabel(\"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWb1SLDXMHSI"
   },
   "source": [
    "## 7. Hypothesis test with randomization\n",
    "\n",
    "<div class=\"alert-warning alert\">Advanced! No obligation to complete this!</div>\n",
    "\n",
    "Is the relationship between age and price different from chance? Use randomization to simulate 1,000 slopes under the null hypothesis that there is no relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbRgFdMa6E-8",
    "tags": []
   },
   "source": [
    "## 8. Simulating data with a regression model with two predictors\n",
    "\n",
    "<div class=\"alert-warning alert\">Advanced! No obligation to complete this!</div>\n",
    "\n",
    "### 8.1. Simulation\n",
    "\n",
    "Of course our model of apartment prices is limited, since there are many other factors influencing the price. Perhaps the most important one is the size of the aparment.\n",
    "\n",
    "1. Create an additional predictor, the size of which ranges from 20 to 200m² with uniform random values.\n",
    "2. We know that for each additional m², the price increases by EUR 2,000.\n",
    "3. Simulate a new price data set that has 2 predictors, age as above, and size as defined here.\n",
    "4. The error should stay the same, but it makes sense to have a lower intercept value of EUR 300 000. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NMCBaEg7f-q"
   },
   "outputs": [],
   "source": [
    "n = 150\n",
    "age = np.random.randint(0, 200, n)\n",
    "sqm2 = np.random.randint(20, 200, n)\n",
    "b1 = -1000\n",
    "b2 = 2000\n",
    "error_sd = 15000\n",
    "price = 300000 + b1 * age + b2 * sqm2 + np.random.normal(0, error_sd, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssFcbC908Ze0"
   },
   "source": [
    "### 8.2. Visualize the data set and ...\n",
    "\n",
    "... (1) make a figure with 2 horizontal subplots (1 for each predictor) and use scatter plots again,\n",
    "\n",
    "... (2) make a new figure with age on the x-axis, and the size of the dots in the scatterplot should be proportional to the size of the apartment (argument `s=` of the scatter plot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "VPIwys4NK4_O",
    "outputId": "ba44941a-c7b3-44c8-8a4a-2c7ca4bacdf9"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(7, 3))\n",
    "ax[0].scatter(age, price)\n",
    "ax[0].set_xlabel(\"age\")\n",
    "ax[0].set_ylabel(\"price €\")\n",
    "\n",
    "ax[1].scatter(sqm2, price)\n",
    "ax[1].set_xlabel(\"Size (m2)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFJzAlPH0B0q"
   },
   "source": [
    "Now let's display both factors on a single figure (size of points as new dimension, `s=` argument):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ODhp7pQKqdHK",
    "outputId": "7e0d5700-46eb-4fbb-b97e-498d420ebbc3"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(age, price, s=sqm2)\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"price €\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wW9OsWaL3pxp"
   },
   "source": [
    "\n",
    "### 8.3. Fit a linear regression model with intercept and the two predictors using `scipy.linalg()` to the above data\n",
    "\n",
    "#### 8.3.1. Calculate the error of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DeSKd-PBxoJA",
    "outputId": "b06514c2-1fa3-46c5-c548-f55b29b98b22"
   },
   "outputs": [],
   "source": [
    "X = np.column_stack((np.ones(n), age, sqm2))\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMsHSqxC1mEH"
   },
   "source": [
    "#### 8.3.2. Observe the fitted coefficients $B_0$,$B_1$,$B_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKnQjyW71kNu",
    "outputId": "0c7d2fa9-e3a9-4099-dca9-2f1cc82a6484"
   },
   "outputs": [],
   "source": [
    "linalg.lstsq(X, price)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbztWHEBzhiC"
   },
   "source": [
    "#### 8.3.3. Fit two regressions to the above data\n",
    "\n",
    "1. intercept and age only as predictors\n",
    "2. only intercept and price as predictors\n",
    "\n",
    "Compare the errors and slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dL2cfUE2zzUF",
    "outputId": "a695c705-4987-4a7b-c1a0-21d5a52915fb"
   },
   "outputs": [],
   "source": [
    "X1 = np.column_stack((np.ones(n), age))\n",
    "\n",
    "print(\n",
    "    \"age only \",\n",
    "    np.round(linalg.lstsq(X1, price)[0], 1),\n",
    "    \"error\",\n",
    "    np.round(np.sqrt(linalg.lstsq(X1, price)[1]), 1),\n",
    ")\n",
    "\n",
    "X2 = np.column_stack((np.ones(n), sqm2))\n",
    "print(\n",
    "    \"Size only \",\n",
    "    np.round(linalg.lstsq(X2, price)[0], 1),\n",
    "    \"error\",\n",
    "    np.round(np.sqrt(linalg.lstsq(X2, price)[1]), 1),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Both \",\n",
    "    np.round(linalg.lstsq(X, price)[0], 1),\n",
    "    \"error\",\n",
    "    np.round(np.sqrt(linalg.lstsq(X, price)[1]), 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xD7rfYuxoWq"
   },
   "source": [
    "---\n",
    "<div class=\"alert alert-info\">Work on one exercise of your choice.</div>\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "### A. Multiple predictors\n",
    "\n",
    "Write a function `my_mult_regr()` to perform the above calculation. This function should take 3 inputs in the following order: 1. predictor (age), 2. predictor (size), 3. outcome variable (price).\n",
    "\n",
    "Your function must\n",
    "1. create a predictor matrix (as above), starting with a column of ones, and the two predictors. (3 columns in total)\n",
    "2. use `lstsq ()` to fit the regression model, as above\n",
    "3. the function should return 2 outputs, the first is an array containing the 3 fitted regression parameters (1st output argument of `lstsq()`), the second output should be the residual error (2nd output argument of lstsq()),\n",
    "\n",
    "Make sure that your function works for inputs of any size (this is important when you add the column of ones), but you can assume that all 3 input vectors have the same length (otherwise the analysis makes no sense).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nY6-bvKW9bCC"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwgXTQkK0kMr"
   },
   "source": [
    "### B. Standardized predictors\n",
    "\n",
    "- Standardize (z-score) your predictors by subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "- Fit a regression with both the single predictor and the two predictor models, and compare the error and the coefficients for fitting the model to standardized and unstandardized data sets.\n",
    "\n",
    "- Make use of the `my_mult_regr()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_nvfnV2sAR6"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGeCcZ-t2msu"
   },
   "source": [
    "## Exercise 2: Car price simulation\n",
    "\n",
    "A new car costs an average of 30,000 Euros. Simulate 200 car prices from the last 70 years, assuming that while cars get cheaper as they get older, very old cars have a vintage value, that is, if they are old enough, they could eventually be worth more than a new car. Use a standard deviation of 10,000 Euros. Hint: Use a linear model for the simulation with two predictors and one linear and one quadratic term. Test different values for the two slopes, simulating data until you are able to simulate realistic car prices that meet the above criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loLoZiIa3u2u"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IC3qE7_p4SWT"
   },
   "source": [
    "Once you have found good values for this simulation, make a nice visualization of the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LhsSPlH4YUH"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAnunXvi0u0e"
   },
   "source": [
    "Once, the data simulation is ready, fit 3 regression models to the simulated data:\n",
    "1. intercept + linear predictor $age$\n",
    "2. intercept + linear predictor $age$ + quadratic predictor $age$<sup>2</sup>\n",
    "3. intercept + linear predictor $age$ + quadratic predictor $age$<sup>2</sup> + cubic predicor $age$<sup>3</sup>\n",
    "\n",
    "`print()` the obtained residual error for the three models and visualize the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sll9VqCw0vlv"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaXB-COv9aI4"
   },
   "source": [
    "## Bonus task: Reliability of regression analysis\n",
    "\n",
    "Since we created the data, we can see how close are the true values to the 'generative' model. Next task is to systematically investigate this relationship. You will have to manipulate the number of datapoints, and the error in the model, and analyze the difference between the data generating and the fitted regression parameters. This task is somewhat analogous to the *t*-test simulation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKIlo7RYAAMY"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
