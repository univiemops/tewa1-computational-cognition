{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5N8uXaLdary"
   },
   "source": [
    "# Tutorial 6 - Part 2 - Regression with categorical predictors\n",
    "\n",
    "*Written and revised by Jozsef Arato, Mengfan Zhang, Dominik Pegler*  \n",
    "Computational Cognition Course, University of Vienna  \n",
    "https://github.com/univiemops/tewa1-computational-cognition\n",
    "\n",
    "---\n",
    "**This tutorial will cover:**\n",
    "\n",
    "*   Categorical predictors\n",
    "*   Interactions\n",
    "*   Training and test set\n",
    "*   Reguralized regression: Ridge and lasso\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-1n3wXvRkNj"
   },
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYKPgkYizkzq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io, linalg, stats\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PV0G57XlR-fu"
   },
   "source": [
    "## 2. Import data\n",
    "\n",
    "### 2.1 Download from moodle: \n",
    "\n",
    "`kidiq.csv`\n",
    "\n",
    "Source:\n",
    "- Gelman, A., Hill, J., &#38; Vehtari, A. (2020). Regression and Other Stories. Cambridge: Cambridge University Press. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "66IvUridA6rm",
    "outputId": "b1be2daf-22a2-4599-e0d4-4e6cf2eb6dee"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkytrLJXSbPL"
   },
   "source": [
    "### 2.2.  Loading data into workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MXOsMdkSYGM"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"kidiq.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mE1ADoFYSggc"
   },
   "source": [
    "## 3. Inspect data set\n",
    "\n",
    "### 3.1. `print` data table, explore number of potential predictors, dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "egmqytVLSqHc",
    "outputId": "6a144e40-5ac7-4926-c474-a0764b9a3920"
   },
   "outputs": [],
   "source": [
    "print(np.shape(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZFb3azYAjiPt",
    "outputId": "086c0e5a-dd53-4ace-8e6b-2d99c98b2cec"
   },
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZTrIyQ3Sq6b"
   },
   "source": [
    "### 3.2. Visualize some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "BG5Wg7trSsWz",
    "outputId": "b665c9b9-ea33-46ef-bd70-bd978520adaf"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2)\n",
    "ax[0].scatter(data[\"mom_iq\"], data[\"kid_score\"], color=\"salmon\", alpha=0.4)\n",
    "ax[0].set_xlabel(\"mom_iq\")\n",
    "ax[0].set_ylabel(\"kid_score\")\n",
    "\n",
    "ax[1].scatter(data[\"mom_hs\"], data[\"kid_score\"], alpha=0.2, color=\"salmon\")\n",
    "ax[1].set_xlabel(\"mom high school\")\n",
    "ax[1].set_ylabel(\"kid_score\")\n",
    "ax[1].set_xticks([0, 1])\n",
    "\n",
    "ax[1].set_xlim([-0.5, 1.5])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roegl4j1TM1H"
   },
   "source": [
    "## 4. Fit a linear regression using two predictors: `mom_hs` and `mom_iq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlRXXvomnj1M"
   },
   "outputs": [],
   "source": [
    "x = np.column_stack((data[\"mom_iq\"], data[\"mom_hs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATVlziw5Th7-",
    "outputId": "ab9eba42-6049-4469-c8e6-cd38b3eb7011"
   },
   "outputs": [],
   "source": [
    "lr = linear_regression()\n",
    "lr.fit(x, data[\"kid_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbU0L5TUTizM"
   },
   "source": [
    "### 4.1. Check the predictor weigths and the score of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1f69NrCTrS-",
    "outputId": "7f5ae23b-a8a3-46a9-a7d2-a47e396c2680"
   },
   "outputs": [],
   "source": [
    "print(\"intercept\", lr.intercept_)\n",
    "print(\"weights/slopes\", lr.coef_)\n",
    "print(\"score: \", lr.score(x, data[\"kid_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVCEx_OSTvMj"
   },
   "source": [
    "### 4.2. Visualize predictions and true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "CWIi6lriT5st",
    "outputId": "264266d1-b5a4-4da1-9452-c7a692cf8b98"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data[\"mom_iq\"], data[\"kid_score\"])\n",
    "\n",
    "ypred = lr.predict(x)\n",
    "plt.plot(data[\"mom_iq\"], ypred, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sa3Ui38CbML_",
    "outputId": "b6797ccf-aa36-4e70-aa7d-a85cfbed9aab"
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdVTBZn9eMAn"
   },
   "source": [
    "#### Solution 1: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "8ot8rtWBqnFG",
    "outputId": "844897b3-1d72-42d6-dd47-1527ff2d33a8"
   },
   "outputs": [],
   "source": [
    "pred_no_high_school = lr.predict(x[x[:, 1] == 0, :])\n",
    "pred_high_school = lr.predict(x[x[:, 1] == 1, :])\n",
    "plt.scatter(data[\"mom_iq\"], data[\"kid_score\"], c=data[\"mom_hs\"])\n",
    "plt.plot(x[x[:, 1] == 0, 0], pred_no_high_school, label=\"no hs\", color=\"blue\")\n",
    "plt.plot(x[x[:, 1] == 1, 0], pred_high_school, label=\"hs\", color=\"orange\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"mom_iq\")\n",
    "plt.ylabel(\"kid_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzlAC65ReQjv"
   },
   "source": [
    "#### Solution 2: Set up a design matrix for prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "k_LU-iKYcdA3",
    "outputId": "ae3ff165-2889-4cb0-f3ad-14c4a368de21"
   },
   "outputs": [],
   "source": [
    "xs = np.array([66, 140])\n",
    "x_no_hs = np.column_stack((xs, np.zeros(2)))\n",
    "print(x_no_hs)\n",
    "xhs = np.column_stack((xs, np.ones(2)))\n",
    "print(xhs)\n",
    "\n",
    "pred_no_high_school = lr.predict(x_no_hs)\n",
    "pred_high_school = lr.predict(xhs)\n",
    "\n",
    "plt.scatter(data[\"mom_iq\"], data[\"kid_score\"], c=data[\"mom_hs\"])\n",
    "plt.plot(xs, pred_no_high_school, label=\"no hs\", color=\"blue\")\n",
    "plt.plot(xs, pred_high_school, label=\"hs\", color=\"orange\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"mom_iq\")\n",
    "plt.ylabel(\"kid_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvT4FduueW7W"
   },
   "source": [
    "#### Solution 3: Indexing + `for` loop for groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "5HwNhnImdnT-",
    "outputId": "72585213-0080-49e3-e093-dd8046821d18"
   },
   "outputs": [],
   "source": [
    "education = [\"no_hs\", \"hs\"]\n",
    "colors = [\"blue\", \"orange\"]\n",
    "plt.scatter(data[\"mom_iq\"], data[\"kid_score\"], c=data[\"mom_hs\"])\n",
    "for ce, e in enumerate(education):\n",
    "    prediciton = lr.predict(x[x[:, 1] == ce, :])\n",
    "    plt.plot(x[x[:, 1] == ce, 0], prediciton, label=e, color=colors[ce])\n",
    "plt.legend()\n",
    "plt.xlabel(\"mom_iq\")\n",
    "plt.ylabel(\"kid_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APYGuiZPTi4V"
   },
   "source": [
    "## 5. Model with interaction\n",
    "\n",
    "Create a new design matrix that includes a column for the interaction between `mom_hs` and `mom_iq`, fit the model and visualize the model prediciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYW2RFEFT_Zm",
    "outputId": "31192d1e-4303-4cf6-e621-a060cc6e442e"
   },
   "outputs": [],
   "source": [
    "x2 = np.column_stack((data[\"mom_iq\"], data[\"mom_hs\"], data[\"mom_iq\"] * data[\"mom_hs\"]))\n",
    "print(\"design matrix with interaction\")\n",
    "print(x2[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNUsRWuMx1Wl",
    "outputId": "1eb14c49-64dc-4034-a3ec-413f81815334"
   },
   "outputs": [],
   "source": [
    "lr.fit(x2, data[\"kid_score\"])\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)\n",
    "print(lr.score(x2, data[\"kid_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "C4tWoZOcyV7V",
    "outputId": "37c1c7df-e6b2-4969-bb43-0b977740b508"
   },
   "outputs": [],
   "source": [
    "education = [\"no_hs\", \"hs\"]\n",
    "colors = [\"blue\", \"orange\"]\n",
    "plt.scatter(data[\"mom_iq\"], data[\"kid_score\"], c=data[\"mom_hs\"])\n",
    "for ce, e in enumerate(education):\n",
    "    prediciton = lr.predict(x2[x2[:, 1] == ce, :])\n",
    "    plt.plot(x2[x2[:, 1] == ce, 0], prediciton, label=e, color=colors[ce])\n",
    "plt.legend()\n",
    "plt.xlabel(\"mom_iq\")\n",
    "plt.ylabel(\"kid_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YqIk--BUKJe"
   },
   "source": [
    "## 6. Learning from data\n",
    "\n",
    "Traditional regression models often fit 100% of the data. While these models learn from the data, they run the risk of overfitting, capturing irrelevant patterns and noise. Furthermore, because they are fit to the entire data set, we cannot evaluate their learning performance or their ability to generalize to new data. On the other hand, more advanced models that are fit to a subset of the data allow us to evaluate the learning process. This evaluation helps us understand the generalization capabilities of the model and assess how well it can make predictions on unseen data.\n",
    "\n",
    "\n",
    "### 6.1. Train-test split\n",
    "\n",
    "The **train-test split** is a technique used to evaluate machine learning and regression models. It involves dividing the dataset into two parts:\n",
    "- Training set: Used to train the model by teaching it the relationships between input and output.\n",
    "- Test set: Reserved to assess the model's performance on new, unseen data.\n",
    "\n",
    "By splitting the dataset, we can train the model on one part and use the other part to see how well it predicts output values for new data.\n",
    "\n",
    "In order to do that we will now separate the X and Y data into an 80% training and 20% test set using indexing. For now, it is okay, just to take the first 80% of data as training and the last 20% as test data (this is clearly a wrong approach if the data is ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3r88-QPUc4j",
    "outputId": "9d92dd2e-1282-4395-e0fb-024879224077"
   },
   "outputs": [],
   "source": [
    "n = len(data[\"kid_score\"])\n",
    "print(n)\n",
    "np.shape(x2[: int(n * 0.8), :])\n",
    "train_x = x2[0 : int(n * 0.8), :]\n",
    "train_y = data[\"kid_score\"][0 : int(n * 0.8)]\n",
    "\n",
    "test_x = x2[int(n * 0.8) :, :]\n",
    "test_y = data[\"kid_score\"][int(n * 0.8) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OzEUJjd2GGw",
    "outputId": "2076dfff-4465-4c61-eb75-e09836543ee1"
   },
   "outputs": [],
   "source": [
    "lr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L60F1T8x2LfP",
    "outputId": "2c5672bd-a42e-4dc2-f001-29f764845ae2"
   },
   "outputs": [],
   "source": [
    "print(lr.score(train_x, train_y))\n",
    "print(lr.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9L2vxJMUd-P"
   },
   "source": [
    "### 6.2. Fit the regression model (with interaction term) on the training set, and calculate the score for both the training and the test sets\n",
    "\n",
    "(randomly selected 80% and 20% test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuFFTidEUuPg"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7AzqaiPV82w"
   },
   "source": [
    "### 6.3. Mean Centering and standardization\n",
    "\n",
    "1. Mean center your data (make a new design matrix for this), and fit and score the model again.\n",
    "\n",
    "2. Standardize your data, and fit again the model with interaction.\n",
    "see how the obtained coefficients and score change\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXssivUJWIpA"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY8PX5S4U4AP"
   },
   "source": [
    "### 6.4.. Regularized regression\n",
    "\n",
    "\n",
    "Test Lasso and Ridge regression on the test and training data from above and see how the score changes, but also how the regression weights (Betas) are influenced.\n",
    "\n",
    "*Note:* Ridge and lasso work well with standardized data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDjLZt72VDZ_"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WPZQabKVD5R"
   },
   "source": [
    "### 6.5. Systematic exploration of Lasso and Ridge\n",
    "\n",
    "Change the Regularization strength alpha systematically for different values and see how this influnces the obtained scores and weigths (both for Lasso and Ridge). Visualize the result of this investigation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqarv_F9VWv_"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQrUvXV8Z-5u"
   },
   "source": [
    "To make more general conclusions, we would need to repeat the training - test serpation mulitple times randomly, and integrate the behavior of lasso and ridge across these mulitple divisions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
